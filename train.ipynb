{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the saved data\n",
    "X = np.load('notes.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'start': np.float64(1.0927083333333334), 'end': np.float64(1.1895833333333332), 'pitch': 71, 'velocity': 60}\n",
      " {'start': np.float64(1.2791666666666666), 'end': np.float64(1.496875), 'pitch': 55, 'velocity': 44}\n",
      " {'start': np.float64(1.4635416666666667), 'end': np.float64(1.6312499999999999), 'pitch': 59, 'velocity': 55}\n",
      " {'start': np.float64(1.6333333333333333), 'end': np.float64(1.753125), 'pitch': 62, 'velocity': 52}]\n"
     ]
    }
   ],
   "source": [
    "print(X[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 1.7865,  1.8281, 72.0000, 76.0000],\n",
      "        [ 1.8031,  2.0000, 67.0000, 56.0000],\n",
      "        [ 1.9833,  2.0979, 74.0000, 68.0000],\n",
      "        [ 2.0375,  2.1063, 72.0000, 77.0000],\n",
      "        [ 2.0979,  2.1823, 74.0000, 51.0000],\n",
      "        [ 2.1719,  2.2802, 67.0000, 57.0000],\n",
      "        [ 2.3281,  2.5094, 66.0000, 58.0000],\n",
      "        [ 2.1490,  2.5198, 72.0000, 60.0000],\n",
      "        [ 1.9833,  2.5229, 57.0000, 61.0000],\n",
      "        [ 2.5229,  2.5896, 71.0000, 68.0000],\n",
      "        [ 2.5906,  2.6740, 72.0000, 47.0000],\n",
      "        [ 2.5583,  2.7635, 64.0000, 35.0000],\n",
      "        [ 2.8875,  3.1135, 62.0000, 63.0000],\n",
      "        [ 3.0802,  3.2729, 66.0000, 63.0000],\n",
      "        [ 2.7125,  3.4198, 59.0000, 50.0000],\n",
      "        [ 2.6792,  3.4479, 74.0000, 68.0000]]), tensor([ 3.4531,  3.6021, 71.0000, 66.0000]))\n",
      "Total number of batches: 110003\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MusicSequenceDataset(Dataset):\n",
    "    def __init__(self, notes, sequence_length):\n",
    "        self.notes = notes  # list of lists of dictionaries (list of sequences of notes)\n",
    "        self.sequence_length = sequence_length  # length of the input sequence\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.notes) - self.sequence_length  # Total number of sequences available\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get a sequence of notes (list of dictionaries)\n",
    "        sequence = self.notes[idx:idx + self.sequence_length]\n",
    "        target = self.notes[idx + self.sequence_length]\n",
    "\n",
    "        # The sequence should now be a flat list of dictionaries, create the tensor for X\n",
    "        X = torch.tensor([[note['start'], note['end'], note['pitch'], note['velocity']] for note in sequence], dtype=torch.float32)\n",
    "        \n",
    "        # The target note is the next note's features\n",
    "        y = torch.tensor([target['start'], target['end'], target['pitch'], target['velocity']], dtype=torch.float32)\n",
    "        \n",
    "        return X, y\n",
    "\n",
    "class MusicLSTMModel(nn.Module):\n",
    "    def __init__(self, input_size=4, hidden_size=128, num_layers=2, output_size=4):\n",
    "        super(MusicLSTMModel, self).__init__()\n",
    "        \n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        \n",
    "        # Fully connected layer to map the hidden state to the output\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass through LSTM layer\n",
    "        lstm_out, (hn, cn) = self.lstm(x)\n",
    "        \n",
    "        # Only take the output of the last time step\n",
    "        last_lstm_output = lstm_out[:, -1, :]\n",
    "        \n",
    "        # Pass the last output through a fully connected layer\n",
    "        output = self.fc(last_lstm_output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "# Instantiate the dataset and DataLoader\n",
    "sequence_length = 16\n",
    "dataset = MusicSequenceDataset(X, sequence_length=sequence_length)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "print(dataset[0])\n",
    "\n",
    "# Assuming you have your DataLoader as `dataloader`\n",
    "total_batches = len(dataloader)\n",
    "print(f\"Total number of batches: {total_batches}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|          | 110003/? [07:15 < 00:00, 252.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Loss: 7642.0334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|          | 110003/? [07:08 < 00:00, 256.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/3], Loss: 447.0842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|          | 110003/? [07:08 < 00:00, 256.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/3], Loss: 424.5167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize the model and move it to the correct device\n",
    "model = MusicLSTMModel()\n",
    "model = model.to(device)\n",
    "\n",
    "epochs = 3\n",
    "learning_rate = 0.001\n",
    "criterion = nn.MSELoss()  # Mean Squared Error for regression tasks\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Example of using a DataLoader (ensure it's initialized correctly elsewhere)\n",
    "# train_loader = DataLoader(...)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Loop over batches in the DataLoader\n",
    "    for batch_idx, (X_batch, y_batch) in tqdm(enumerate(dataloader), bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed} < {remaining}, {rate_fmt}]\"):\n",
    "        optimizer.zero_grad()  # Zero out previous gradients\n",
    "\n",
    "        # Move batch data to device (GPU or CPU)\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(X_batch)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, y_batch)  # Compare predicted outputs with actual targets\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()  # Compute gradients\n",
    "        optimizer.step()  # Update the model parameters\n",
    "\n",
    "        # Accumulate the running loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print the loss for this epoch\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss / len(dataloader):.4f}\")\n",
    "\n",
    "torch.save(model.state_dict(), f\"model_epoch_{epoch+1}.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
